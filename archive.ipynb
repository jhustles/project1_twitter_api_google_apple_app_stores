{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Mining Function & Scatter Plots\n",
    "---------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies\n",
    "%matplotlib notebook\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "import requests\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from twython import Twython\n",
    "import simplejson\n",
    "import sys\n",
    "import string\n",
    "import glob\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Twitter 'Keys' - MUST SET UP YOUR OWN 'config_twt.py' file\n",
    "# You will need to create your own \"config_twt.py\" file using each of the Twitter authentication codes\n",
    "# they provide you when you sign up for a developer account with your Twitter handle\n",
    "from config_twt import (app_key_twt, app_secret_twt, oauth_token_twt, oauth_token_secret_twt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Up Consumer Keys And Secret with Twitter Keys\n",
    "APP_KEY = app_key_twt\n",
    "APP_SECRET = app_secret_twt\n",
    "\n",
    "# Set up OAUTH Token and Secret With Twitter Keys\n",
    "\n",
    "OAUTH_TOKEN = oauth_token_twt\n",
    "OAUTH_TOKEN_SECRET = oauth_token_secret_twt\n",
    "\n",
    "# Load Keys In To a Twython Function And Call It \"twitter\"\n",
    "twitter = Twython(APP_KEY, APP_SECRET, OAUTH_TOKEN, OAUTH_TOKEN_SECRET)\n",
    "\n",
    "# Setup Batch Counter For Phase 2\n",
    "batch_counter = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________\n",
    "## Twitter Mining Function '(TMF)'\n",
    "___________________________\n",
    "\n",
    "### INSTRUCTIONS:\n",
    "\n",
    "\n",
    "This will Twitter Query Function will:\n",
    "- Perform searches for hastags (#)\n",
    "- Search for \"@twitter_user_acct\"\n",
    "- Provide mixed results of popular and most recent tweets from the last 7 days\n",
    "- 'remaining' 'search/tweets (allowance of 180) rate limit status' regenerates in 15 minutes after depletion\n",
    "\n",
    "### Final outputs are aggegrated queries in both:\n",
    "\n",
    "- Pandas DataFrame of queried tweets\n",
    "- CSV files saved in the same folder as this Jupyter Notebook\n",
    "\n",
    "\n",
    "### Phase 1 - Run Query and Store The Dictionary Into a List\n",
    "\n",
    "\n",
    "- Step 1) Run the 'Twitter Mining Function' cell below to begin program\n",
    "            Note:\n",
    "                - Limits have not been fully tested due to time constraint\n",
    "                - Search up to 180 queries where and each query yields up to 100 tweets max\n",
    "                - Running the TLC to see how many you have left after every csv outputs.\n",
    "\n",
    "- Step 2) When prompted, input in EITHER: #hashtag or  @Twitter_user_account\n",
    "            Examples: \"#thuglife\" or \"@beyonce\"\n",
    "\n",
    "- Step 3) TMF will query Twitter and store the tweets_data, a list called \"all_data\"\n",
    "\n",
    "- Step 4) Upon query search completion, it will prompt: \"Perform another search query:'  ('y'/'n')  \"\n",
    "            - Input 'y' to query, and the program will append the results\n",
    "            - Tip: Keep count of how many 'search tweets' you have, it should deduct 1 from 'remaining',\n",
    "                    which can produce up to 100 tweets of data\n",
    "                    \n",
    "- Step 5) End program by entering 'n' when prompted for 'search again'\n",
    "            Output: printed list of all appended query data\n",
    "\n",
    "\n",
    "### Phase 2 - Converting to Pandas DataFrame and Produce a CSV Output\n",
    "\n",
    "- Step 6) Loop Through Queried Data \n",
    "\n",
    "- Step 7) Convert to Pandas DataFrame\n",
    "\n",
    "- Step 8) Convert from DataFrame to CSV\n",
    "\n",
    "### Addtional Considerations:\n",
    "\n",
    "- Current set up uses standard search api keys, not premium\n",
    "- TMF returns potentially 100 tweets at a time, and pulls from the last 7 days in random order\n",
    "- More than likely will have to run multiple searches and track line items count\n",
    "    in each of the csv files output that will be created in the same folder\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Limit Counter (TLC)\n",
    "    - Run cell to see how many search queries you have available\n",
    "    - Your 'remaining' search tweets regenerates over 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TLC - Run to Query Current Rate Limit on API Keys    \n",
    "twitter.get_application_rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Twitter Mining Function (TMF)\n",
    "#RUN THIS CELL TO BEGIN PROGRAM!\n",
    "print('-'*80)\n",
    "print(\"TWITTER QUERY FUNCTION - BETA\")\n",
    "print('-'*80)\n",
    "print(\"INPUT PARAMETERS:\")\n",
    "print(\"- @Twitter_handle e.g. @clashofclans\")\n",
    "print(\"- Hashtags (#) e.g. #THUGLIFE\")\n",
    "print(\"NOTE: SCROLL DOWN AFTER EACH QUERY FOR ENTER INPUT\")\n",
    "print('-'*80)\n",
    "\n",
    "def twitter_search(app_search):\n",
    "        # Store the following Twython function and parameters into variable 't'\n",
    "        t = Twython(app_key=APP_KEY,\n",
    "                   app_secret=APP_SECRET,\n",
    "                   oauth_token=OAUTH_TOKEN,\n",
    "                   oauth_token_secret=OAUTH_TOKEN_SECRET)\n",
    "        # The Twitter Mining Function we will use to run searches is below\n",
    "        # and we're asking for it to pull 100 tweets\n",
    "        search = t.search(q=app_search, count=100)\n",
    "        tweets = search['statuses']\n",
    "    # This will be a list of dictionaries of each tweet where the loop below will append to\n",
    "        all_data = []\n",
    "    # From the tweets, go into each individual tweet and extract the following into a 'dictionary'\n",
    "    # and append it to big bucket called 'all_data'\n",
    "        for tweet in tweets:\n",
    "            try:\n",
    "                tweets_data = {\n",
    "                    \"Created At\":tweet['created_at'],\n",
    "                    \"Text (Tweet)\":tweet['text'],\n",
    "                    \"User ID\":tweet['user']['id'],\n",
    "                    \"User Followers Count\":tweet['user']['followers_count'],\n",
    "                    \"Screen Name\":tweet['user']['name'],\n",
    "                     \"ReTweet Count\":tweet['retweet_count'],\n",
    "                     \"Favorite Count\":tweet['favorite_count']}\n",
    "                all_data.append(tweets_data)\n",
    "                #print(tweets_data)\n",
    "            except (KeyError, NameError, TypeError, AttributeError) as err:      \n",
    "                print(f\"{err}    Skipping...\")\n",
    "                #functions need to return something...\n",
    "        return all_data\n",
    "# The On and Off Mechanisms:\n",
    "search_again = 'y'\n",
    "final_all_data = []\n",
    "# initialize the query counter\n",
    "query_counter = 0\n",
    "while search_again == 'y':\n",
    "    query_counter += 1\n",
    "    start_program = str(input('Type the EXACT @twitter_acct or #hashtag to query:   '))\n",
    "    all_data = twitter_search(start_program)\n",
    "    final_all_data += all_data\n",
    "    #print(all_data)\n",
    "    print(f\"Completed Collecting Search Results for {start_program} . Queries Completed: {query_counter} \")\n",
    "    print('-'*80)\n",
    "    search_again = input(\"Would you like to run another query? Enter 'y'. Otherwise, 'n' or another response will end query mode. \")\n",
    "    print('-'*80)\n",
    "# When you exit the program, set the query counter back to zero\n",
    "query_counter = 0\n",
    "print()\n",
    "print(f\"Phase 1 of 2 Queries Completed . Proceed to Phase 2 - Convert Collection to DF and CSV formats .\")\n",
    "#print(\"final Data\", final_all_data)\n",
    "#####################################################################################################\n",
    "# TIPS!: # If you're searching for the same hastag or twitter_handle,\n",
    "         # consider copying and pasting it (e.g. @fruitninja)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the total tweets the TMF successfully pulled:\n",
    "print(len(final_all_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Limit Counter (TLC)\n",
    "    - Run cell to see how many search queries you have available\n",
    "    - Your 'remaining' search tweets regenerates over 15 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run to view current rate limit status\n",
    "twitter.get_application_rate_limit_status()['resources']['search']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(final_all_data[0])\n",
    "#df\n",
    "\n",
    "final_all_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6) Loop through the stored list of queried tweets from final_all_data and stores in designated lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop thru finall_all_data (list of dictionaries) and extract each item and store them into\n",
    "# the respective lists\n",
    "\n",
    "# BUCKETS\n",
    "created_at = []\n",
    "tweet_text = []\n",
    "user_id = []\n",
    "user_followers_count = []\n",
    "screen_name = []\n",
    "retweet_count = []\n",
    "likes_count = []\n",
    "\n",
    "# append tweets data to the buckets for each tweet\n",
    "#change to final_all_data\n",
    "for data in final_all_data:\n",
    "        #print(keys, data[keys])\n",
    "        \n",
    "    created_at.append(data[\"Created At\"]),\n",
    "    tweet_text.append(data['Text (Tweet)']),\n",
    "    user_id.append(data['User ID']),\n",
    "    user_followers_count.append(data['User Followers Count']),\n",
    "    screen_name.append(data['Screen Name']),\n",
    "    retweet_count.append(data['ReTweet Count']),\n",
    "    likes_count.append(data['Favorite Count'])\n",
    "\n",
    "\n",
    "#print(created_at, tweet_text, user_id, user_followers_count, screen_name, retweet_count, likes_count)\n",
    "\n",
    "print(\"Run complete. Proceed to next cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7) Convert to Pandas DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Setup DataFrame and run tweets_data_df\n",
    "\n",
    "tweets_data_df = pd.DataFrame({\n",
    "    \"Created At\": created_at,\n",
    "    \"Screen Name\": screen_name,\n",
    "    \"User ID\": user_id,\n",
    "    \"User Follower Count\": user_followers_count,\n",
    "    \"Likes Counts\": likes_count,\n",
    "    \"ReTweet Count\": retweet_count,\n",
    "    \"Tweet Text\" : tweet_text\n",
    "})\n",
    "tweets_data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8) Load into MySQL Database - later added this piece to display ETL potential of this project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This section was added later after I reviewed and wanted to briefly reiterate on it\n",
    "tweets_data_df2 = tweets_data_df.copy()\n",
    "# Dropped Screen Name and Tweets Text bc would I would need to clean the 'Screen Name' and 'Tweet Text' Columns\n",
    "tweets_data_df2 = tweets_data_df2.drop([\"Screen Name\", \"Tweet Text\"], axis=1).sort_values(by=\"User Follower Count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Dependencies 2/2:\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.sql import select\n",
    "from sqlalchemy_utils import database_exists, create_database, drop_database, has_index\n",
    "import pymysql\n",
    "\n",
    "rds_connection_string = \"root:PASSWORD_HERE@127.0.0.1/\"\n",
    "#db_name = input(\"What database would you like to search for?\")\n",
    "db_name = 'twitterAPI_data_2019_db'\n",
    "# Setup engine connection string\n",
    "engine = create_engine(f'mysql://{rds_connection_string}{db_name}?charset=utf8', echo=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Created a function incorproating SQL Alchemy to search, create, and or drop a database:\n",
    "def search_create_drop_db(db_name):\n",
    "    db_exist = database_exists(f'mysql://{rds_connection_string}{db_name}')\n",
    "    db_url = f'mysql://{rds_connection_string}{db_name}'\n",
    "    if db_exist == True:\n",
    "        drop_table_y_or_n = input(f'\"{db_name}\" database already exists in MySQL. Do you want you drop the table? Enter exactly: \"y\" or \"n\".  ')\n",
    "        if drop_table_y_or_n == 'y':\n",
    "            drop_database(db_url)\n",
    "            print(f\"Database {db_name} was dropped\")\n",
    "            create_new_db = input(f\"Do you want to create another database called: {db_name}?  \")\n",
    "            if create_new_db == 'y':\n",
    "                create_database(db_url)\n",
    "                return(f\"The database {db_name} was created. Next You will need to create tables for this database.  \")\n",
    "            else:\n",
    "                return(\"No database was created. Goodbye!  \")\n",
    "        else:\n",
    "            return(\"The database exists. No action was taken. Goodbye!  \")\n",
    "    else:\n",
    "        create_database(db_url)\n",
    "        return(f\"The queried database did not exist, and was created as: {db_name} .  \")\n",
    "search_create_drop_db(db_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_data_df2.to_sql('tweets', con=engine, if_exists='append')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 9) Convert DataFrame to CSV File and save on local drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Save Tweets Data to a CSV File (Run Cell to input filename)\n",
    "# Streamline the saving of multiple queries (1 query = up to 100 tweets) into a csv file.\n",
    "\n",
    "# E.g. input = (#fruit_ninja) will save the file as \"fruit_ninja_batch1.csv\" as the file result\n",
    "# Note: first chracter will be slice off so you can just copy and paste\n",
    "# the hastag / @twitter_handle from steps above\n",
    "batch_name = str(input(\"Enter in batch name.\"))\n",
    "\n",
    "# If you restart kernel, batch_counter resets to zero.\n",
    "batch_counter = batch_counter +1\n",
    "\n",
    "# Check if the #hastag / @twitter_handle folder exists and create the folder if it does not\n",
    "Path(f\"./resources/{batch_name[1:]}\").mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save dataframe of all queries in a csv file to a folder in the resources folder csv using the \n",
    "tweets_data_df.to_csv(f\"./resources/{batch_name[1:]}/{batch_name[1:]}_batch{batch_counter}.csv\", encoding='utf-8')\n",
    "print(f\"Output saved in current folder as: {batch_name[1:]}_batch{batch_counter}.csv \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PHASE 3 -  CALCULATIONS USING API DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All folders in the 'resources' folder:\n",
      "========================================\n",
      "\n",
      "Total Folders: 2\n"
     ]
    }
   ],
   "source": [
    "# This prints out all of the folder titles in \"resources\" folder\n",
    "path = './resources/*' # use your path\n",
    "resources = glob.glob(path)\n",
    "\n",
    "all_folders = []\n",
    "print(\"All folders in the 'resources' folder:\")\n",
    "print(\"=\"*40)\n",
    "for foldername in resources:\n",
    "    str(foldername)\n",
    "    foldername = foldername[12:]\n",
    "    all_folders.append(foldername)\n",
    "#print(li)\n",
    "print(\"\")\n",
    "print(F\"Total Folders: {len(all_folders)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['angrybirds', 'bible']\n"
     ]
    }
   ],
   "source": [
    "print(all_folders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_TopApps_df_list = []\n",
    "\n",
    "for foldername in all_folders:\n",
    "    plug = foldername\n",
    "    path = f'./resources\\\\{plug}'\n",
    "    all_files = glob.glob(path + \"/*.csv\")\n",
    "    counter = 0\n",
    "    app_dataframes = []\n",
    "    for filename in all_files:\n",
    "        counter += 1\n",
    "        df = pd.read_csv(filename, index_col=None, header=0)\n",
    "        app_dataframes.append(df)\n",
    "    output = pd.concat(app_dataframes, axis=0, ignore_index=True)\n",
    "    all_TopApps_df_list.append(f\"{output}_{counter}\")\n",
    "    counter = 0\n",
    "    #fb_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Facebook Calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example Template of looping thru csvfiles, and concatenate all of the csv files we collected in each folder\n",
    "plug = 'facebook'\n",
    "path = f'./resources\\\\{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "fb_frame = pd.concat(li, axis=0, ignore_index=True)\n",
    "fb_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fb_frame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "fb_frame.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "facebook_filtered_df = fb_frame.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "facebook_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "facebook_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "facebook_total_tweets = len(facebook_filtered_df['Tweet Text'])\n",
    "facebook_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "facebook_avg_followers_ct = facebook_filtered_df['User Follower Count'].mean()\n",
    "facebook_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "facebook_total_likes = facebook_filtered_df['Likes Counts'].sum()\n",
    "#facebook_avg_likes = facebook_filtered_df['Likes Counts'].mean()\n",
    "facebook_total_likes\n",
    "#facebook_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Facebook Retweets Stats:\n",
    "#facebook_sum_retweets = facebook_filtered_df['ReTweet Count'].sum()\n",
    "facebook_avg_retweets = facebook_filtered_df['ReTweet Count'].mean()\n",
    "#facebook_sum_retweets\n",
    "facebook_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Instagram Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'instagram'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "instagram_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "instagram_source_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snapshot Statistics\n",
    "instagram_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "instagram_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "instagram_filtered_df = instagram_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instagram_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "instagram_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "instagram_total_tweets = len(instagram_filtered_df['Tweet Text'])\n",
    "instagram_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "instagram_avg_followers_ct = instagram_filtered_df['User Follower Count'].mean()\n",
    "instagram_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "instagram_total_likes = instagram_filtered_df['Likes Counts'].sum()\n",
    "#instagram_avg_likes = instagram_filtered_df['Likes Counts'].mean()\n",
    "instagram_total_likes\n",
    "#instagram_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#instagram_sum_retweets = instagram_filtered_df['ReTweet Count'].sum()\n",
    "instagram_avg_retweets = instagram_filtered_df['ReTweet Count'].mean()\n",
    "#instagram_sum_retweets\n",
    "instagram_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clash of Clans Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'clashofclans'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "coc_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "coc_source_df\n",
    "\n",
    "# Snapshot Statistics\n",
    "coc_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coc_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "coc_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "coc_filtered_df = coc_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coc_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "coc_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "coc_total_tweets = len(coc_filtered_df['Tweet Text'])\n",
    "coc_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "coc_avg_followers_ct = coc_filtered_df['User Follower Count'].mean()\n",
    "coc_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "coc_total_likes = coc_filtered_df['Likes Counts'].sum()\n",
    "#coc_avg_likes = coc_filtered_df['Likes Counts'].mean()\n",
    "coc_total_likes\n",
    "#coc_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#coc_sum_retweets = coc_filtered_df['ReTweet Count'].sum()\n",
    "coc_avg_retweets = coc_filtered_df['ReTweet Count'].mean()\n",
    "#coc_sum_retweets\n",
    "coc_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Temple Run Calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'templerun'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "templerun_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "templerun_source_df\n",
    "\n",
    "# Snapshot Statistics\n",
    "templerun_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#templerun_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "templerun_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "templerun_filtered_df = templerun_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#templerun_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#templerun_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "templerun_total_tweets = len(templerun_filtered_df['Tweet Text'])\n",
    "templerun_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "templerun_avg_followers_ct = templerun_filtered_df['User Follower Count'].mean()\n",
    "templerun_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "templerun_total_likes = templerun_filtered_df['Likes Counts'].sum()\n",
    "#templerun_avg_likes = templerun_filtered_df['Likes Counts'].mean()\n",
    "templerun_total_likes\n",
    "#instagram_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#templerun_sum_retweets = templerun_filtered_df['ReTweet Count'].sum()\n",
    "templerun_avg_retweets = templerun_filtered_df['ReTweet Count'].mean()\n",
    "#templerun_sum_retweets\n",
    "templerun_avg_retweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "templerun_total_tweets\n",
    "templerun_avg_retweets\n",
    "templerun_avg_followers_ct\n",
    "templerun_total_likes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandora Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'pandora'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "pandora_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "pandora_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pandora_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "pandora_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "pandora_filtered_df = pandora_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandora_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "pandora_total_tweets = len(pandora_filtered_df['Tweet Text'])\n",
    "pandora_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "pandora_avg_followers_ct = pandora_filtered_df['User Follower Count'].mean()\n",
    "pandora_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "# use sum of likes.\n",
    "pandora_total_likes = pandora_filtered_df['Likes Counts'].sum()\n",
    "#pandora_avg_likes = pandora_filtered_df['Likes Counts'].mean()\n",
    "pandora_total_likes\n",
    "#pandora_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#pandora_sum_retweets = pandora_filtered_df['ReTweet Count'].sum()\n",
    "pandora_avg_retweets = pandora_filtered_df['ReTweet Count'].mean()\n",
    "#pandora_sum_retweets\n",
    "pandora_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pinterest Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate them\n",
    "plug = 'pinterest'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "pinterest_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "pinterest_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinterest_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "pinterest_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "pinterest_filtered_df = pinterest_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinterest_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pinterest_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "pinterest_total_tweets = len(pinterest_filtered_df['Tweet Text'])\n",
    "pinterest_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "pinterest_avg_followers_ct = pinterest_filtered_df['User Follower Count'].mean()\n",
    "pinterest_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "pinterest_total_likes = pinterest_filtered_df['Likes Counts'].sum()\n",
    "#pinterest_avg_likes = pinterest_filtered_df['Likes Counts'].mean()\n",
    "pinterest_total_likes\n",
    "#pinterest_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#pinterest_sum_retweets = pinterest_filtered_df['ReTweet Count'].sum()\n",
    "pinterest_avg_retweets = pinterest_filtered_df['ReTweet Count'].mean()\n",
    "#pinterest_sum_retweets\n",
    "pinterest_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bible (You Version) Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'bible'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "bible_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "bible_source_df\n",
    "# Snapshot Statistics\n",
    "bible_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "bible_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "bible_filtered_df = bible_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bible_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "bible_total_tweets = len(bible_filtered_df['Tweet Text'])\n",
    "bible_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Avg Followers - doesn't make sense to sum.\n",
    "bible_avg_followers_ct = bible_filtered_df['User Follower Count'].mean()\n",
    "bible_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "bible_total_likes = bible_filtered_df['Likes Counts'].sum()\n",
    "#bible_avg_likes = bible_filtered_df['Likes Counts'].mean()\n",
    "bible_total_likes\n",
    "#bible_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#bible_sum_retweets = bible_filtered_df['ReTweet Count'].sum()\n",
    "bible_avg_retweets = bible_filtered_df['ReTweet Count'].mean()\n",
    "#bible_sum_retweets\n",
    "bible_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candy Crush Saga Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'candycrushsaga'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "CandyCrushSaga_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "CandyCrushSaga_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has duplicates\n",
    "CandyCrushSaga_source_df.sort_values(by=['User ID','Created At'], ascending=False)\n",
    "CandyCrushSaga_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "CandyCrushSaga_filtered_df = CandyCrushSaga_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "CandyCrushSaga_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CandyCrushSaga_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "candycrushsaga_total_tweets = len(CandyCrushSaga_filtered_df['Tweet Text'])\n",
    "candycrushsaga_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Avg Followers - doesn't make sense to sum.\n",
    "candycrushsaga_avg_followers_ct = CandyCrushSaga_filtered_df['User Follower Count'].mean()\n",
    "candycrushsaga_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "candycrushsaga_total_likes = CandyCrushSaga_filtered_df['Likes Counts'].sum()\n",
    "#facebook_avg_likes = facebook_filtered_df['Likes Counts'].mean()\n",
    "candycrushsaga_total_likes\n",
    "#facebook_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#facebook_sum_retweets = facebook_filtered_df['ReTweet Count'].sum()\n",
    "candycrushsaga_avg_retweets = CandyCrushSaga_filtered_df['ReTweet Count'].mean()\n",
    "#facebook_sum_retweets\n",
    "candycrushsaga_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spotify Music Caculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'spotify'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "spotify_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "spotify_source_df.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "spotify_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "spotify_filtered_df = spotify_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "spotify_total_tweets = len(spotify_filtered_df['Tweet Text'])\n",
    "spotify_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "spotify_avg_followers_ct = spotify_filtered_df['User Follower Count'].mean()\n",
    "spotify_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "spotify_total_likes = spotify_filtered_df['Likes Counts'].sum()\n",
    "#spotify_avg_likes = spotify_filtered_df['Likes Counts'].mean()\n",
    "spotify_total_likes\n",
    "#spotify_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#spotify_sum_retweets = spotify_filtered_df['ReTweet Count'].sum()\n",
    "spotify_avg_retweets = spotify_filtered_df['ReTweet Count'].mean()\n",
    "#spotify_sum_retweets\n",
    "spotify_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Angry Birds Calculations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'angrybirds'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "angrybirds_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "angrybirds_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angrybirds_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort to set up removal of duplicates\n",
    "angrybirds_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "angrybirds_filtered_df = angrybirds_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angrybirds_filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "angrybirds_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "angrybirds_total_tweets = len(angrybirds_filtered_df['Tweet Text'])\n",
    "angrybirds_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate angrybirds Avg Followers - doesn't make sense to sum.\n",
    "angrybirds_avg_followers_ct = angrybirds_filtered_df['User Follower Count'].mean()\n",
    "angrybirds_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "angrybirds_total_likes = angrybirds_filtered_df['Likes Counts'].sum()\n",
    "#angrybirds_avg_likes = angrybirds_filtered_df['Likes Counts'].mean()\n",
    "angrybirds_total_likes\n",
    "#angrybirds_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retweets Stats:\n",
    "#angrybirds_sum_retweets = angrybirds_filtered_df['ReTweet Count'].sum()\n",
    "angrybirds_avg_retweets = angrybirds_filtered_df['ReTweet Count'].mean()\n",
    "#angrybirds_sum_retweets\n",
    "angrybirds_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YouTube Calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'youtube'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "youtube_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "youtube_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort\n",
    "youtube_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "youtube_filtered_df = youtube_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "youtube_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "youtube_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "youtube_total_tweets = len(youtube_filtered_df['Tweet Text'])\n",
    "youtube_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "youtube_avg_followers_ct = youtube_filtered_df['User Follower Count'].mean()\n",
    "youtube_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "# use sum of likes.\n",
    "youtube_total_likes = youtube_filtered_df['Likes Counts'].sum()\n",
    "#youtube_avg_likes = youtube_filtered_df['Likes Counts'].mean()\n",
    "youtube_total_likes\n",
    "#youtube_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You Tube Retweets Stats:\n",
    "#youtube_sum_retweets = facebook_filtered_df['ReTweet Count'].sum()\n",
    "youtube_avg_retweets = youtube_filtered_df['ReTweet Count'].mean()\n",
    "#youtube_sum_retweets\n",
    "youtube_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subway Surfers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'subwaysurfer'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "SubwaySurfers_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "SubwaySurfers_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubwaySurfers_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort\n",
    "SubwaySurfers_source_df.sort_values(by=['User ID','Created At'], ascending=False)\n",
    "SubwaySurfers_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "SubwaySurfers_filtered_df = SubwaySurfers_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "SubwaySurfers_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SubwaySurfers_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "SubwaySurfers_total_tweets = len(SubwaySurfers_filtered_df['Tweet Text'])\n",
    "SubwaySurfers_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Avg Followers - doesn't make sense to sum.\n",
    "SubwaySurfers_avg_followers_ct = SubwaySurfers_filtered_df['User Follower Count'].mean()\n",
    "SubwaySurfers_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "SubwaySurfers_total_likes = SubwaySurfers_filtered_df['Likes Counts'].sum()\n",
    "#SubwaySurfers_avg_likes = SubwaySurfers_filtered_df['Likes Counts'].mean()\n",
    "SubwaySurfers_total_likes\n",
    "#SubwaySurfers_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subway Surfer Retweets Stats:\n",
    "#SubwaySurfers_sum_retweets = SubwaySurfers_filtered_df['ReTweet Count'].sum()\n",
    "SubwaySurfers_avg_retweets = SubwaySurfers_filtered_df['ReTweet Count'].mean()\n",
    "#SubwaySurfers_sum_retweets\n",
    "SubwaySurfers_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Security Master - Antivirus, VPN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cheetah Mobile owns Security Master\n",
    "plug = 'cheetah'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "SecurityMaster_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "SecurityMaster_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecurityMaster_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has duplicates\n",
    "SecurityMaster_source_df.sort_values(by=['User ID','Created At'], ascending=False)\n",
    "SecurityMaster_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "SecurityMaster_filtered_df = SecurityMaster_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "SecurityMaster_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SecurityMaster_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "SecurityMaster_total_tweets = len(SecurityMaster_filtered_df['Tweet Text'])\n",
    "SecurityMaster_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Avg Followers - doesn't make sense to sum.\n",
    "SecurityMaster_avg_followers_ct = SecurityMaster_filtered_df['User Follower Count'].mean()\n",
    "SecurityMaster_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "SecurityMaster_total_likes = SecurityMaster_filtered_df['Likes Counts'].sum()\n",
    "#SecurityMaster_avg_likes = SecurityMaster_filtered_df['Likes Counts'].mean()\n",
    "SecurityMaster_total_likes\n",
    "#SecurityMaster_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security Master Retweets Stats:\n",
    "#SecurityMaster_sum_retweets = SecurityMaster_filtered_df['ReTweet Count'].sum()\n",
    "SecurityMaster_avg_retweets = SecurityMaster_filtered_df['ReTweet Count'].mean()\n",
    "#SecurityMaster_sum_retweets\n",
    "SecurityMaster_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clash Royale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'clashroyale'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "ClashRoyale_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "ClashRoyale_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClashRoyale_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has duplicates\n",
    "ClashRoyale_source_df.sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "ClashRoyale_filtered_df = ClashRoyale_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "ClashRoyale_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ClashRoyale_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "ClashRoyale_total_tweets = len(ClashRoyale_filtered_df['Tweet Text'])\n",
    "ClashRoyale_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Avg Followers - doesn't make sense to sum.\n",
    "ClashRoyale_avg_followers_ct = ClashRoyale_filtered_df['User Follower Count'].mean()\n",
    "ClashRoyale_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "ClashRoyale_total_likes = ClashRoyale_filtered_df['Likes Counts'].sum()\n",
    "#ClashRoyale_avg_likes = ClashRoyale_filtered_df['Likes Counts'].mean()\n",
    "ClashRoyale_total_likes\n",
    "#ClashRoyale_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ClashRoyale Retweets Stats:\n",
    "#ClashRoyale_sum_retweets = ClashRoyale_filtered_df['ReTweet Count'].sum()\n",
    "ClashRoyale_avg_retweets = ClashRoyale_filtered_df['ReTweet Count'].mean()\n",
    "#facebook_sum_retweets\n",
    "ClashRoyale_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Master - Space Cleaner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'cleanmaster'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "CleanMaster_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "CleanMaster_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanMaster_source_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has duplicates\n",
    "CleanMaster_source_df.sort_values(by=['User ID','Created At'], ascending=False)\n",
    "CleanMaster_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "CleanMaster_filtered_df = CleanMaster_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "CleanMaster_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CleanMaster_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "CleanMaster_total_tweets = len(CleanMaster_filtered_df['Tweet Text'])\n",
    "CleanMaster_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Avg Followers - doesn't make sense to sum.\n",
    "CleanMaster_avg_followers_ct = CleanMaster_filtered_df['User Follower Count'].mean()\n",
    "CleanMaster_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets\n",
    "CleanMaster_total_likes = CleanMaster_filtered_df['Likes Counts'].sum()\n",
    "#facebook_avg_likes = facebook_filtered_df['Likes Counts'].mean()\n",
    "CleanMaster_total_likes\n",
    "#facebook_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean MasterRetweets Stats:\n",
    "#CleanMaster_sum_retweets = CleanMaster_filtered_df['ReTweet Count'].sum()\n",
    "CleanMaster_avg_retweets = CleanMaster_filtered_df['ReTweet Count'].mean()\n",
    "#facebook_sum_retweets\n",
    "CleanMaster_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plug = 'whatsapp'\n",
    "path = f'./resources/{plug}'\n",
    "all_files = glob.glob(path + \"/*.csv\")\n",
    "li = []\n",
    "for filename in all_files:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0)\n",
    "    li.append(df)\n",
    "whatsapp_source_df = pd.concat(li, axis=0, ignore_index=True)\n",
    "\n",
    "# Snapshot Statistics\n",
    "whatsapp_source_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatsapp_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# has duplicates\n",
    "whatsapp_source_df.sort_values(by=['User ID','Created At'], ascending=False)\n",
    "whatsapp_source_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop Duplicates only for matching columns omitting the index\n",
    "whatsapp_filtered_df = whatsapp_source_df.drop_duplicates(['Created At', 'Screen Name', 'User ID', 'User Follower Count', 'Likes Counts', 'ReTweet Count', 'Tweet Text']).sort_values(by=['User ID','Created At'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get New Snap Shot Statistics\n",
    "whatsapp_filtered_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "whatsapp_filtered_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count total out of Unique Tweets\n",
    "whatsapp_total_tweets = len(whatsapp_filtered_df['Tweet Text'])\n",
    "whatsapp_total_tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Facebook Avg Followers - doesn't make sense to sum.\n",
    "whatsapp_avg_followers_ct = whatsapp_filtered_df['User Follower Count'].mean()\n",
    "whatsapp_avg_followers_ct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Total Likes of all tweets.\n",
    "whatsapp_total_likes = whatsapp_filtered_df['Likes Counts'].sum()\n",
    "#whatsapp_avg_likes = whatsapp_filtered_df['Likes Counts'].mean()\n",
    "whatsapp_total_likes\n",
    "#whatsapp_avg_likes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Whatsapp Retweets Stats:\n",
    "#whatsapp_sum_retweets = whatsapp_filtered_df['ReTweet Count'].sum()\n",
    "whatsapp_avg_retweets = whatsapp_filtered_df['ReTweet Count'].mean()\n",
    "#whatsapp_sum_retweets\n",
    "whatsapp_avg_retweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charts and Plots\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot - Twitter Average Followers to Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot 1 - Tweets vs Average Followers vs Total Likes of the Top 10 Apps for both Google and Apple App Stores\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,11))\n",
    "\n",
    "\n",
    "# Apps both on Google Play Store and Apple - 4 apps\n",
    "facebook_plot = ax.scatter(facebook_total_tweets, facebook_avg_followers_ct, s=facebook_total_likes*15, color='sandybrown', label='Facebook', edgecolors='black', alpha=0.75)\n",
    "instagram_plot= ax.scatter(instagram_total_tweets, instagram_avg_followers_ct, s=instagram_total_likes*15, color='saddlebrown', label='Instagram', edgecolors='black', alpha=0.5)\n",
    "coc_plot= ax.scatter(coc_total_tweets, coc_avg_followers_ct, s=coc_total_likes*10, color='springgreen', label='Clash Of Clans', edgecolors='black', alpha=0.75)\n",
    "candycrushsaga_plot= ax.scatter(candycrushsaga_total_tweets, candycrushsaga_avg_followers_ct, s=candycrushsaga_total_likes*5, color='limegreen', label='Candy Crush Saga', edgecolors='black')#, alpha=0.75)\n",
    "\n",
    "# Google Play Store - 6 apps:\n",
    "CleanMaster_plot= ax.scatter(CleanMaster_total_tweets, CleanMaster_avg_followers_ct, s=CleanMaster_total_likes*5, color='m', label='Clean Master Space Cleaner', edgecolors='black', alpha=0.75)\n",
    "SubwaySurfers_plot= ax.scatter(SubwaySurfers_total_tweets, SubwaySurfers_avg_followers_ct, s=SubwaySurfers_total_likes*5, color='lime', label='Subway Surfers', edgecolors='black', alpha=0.75)\n",
    "youtube_plot= ax.scatter(youtube_total_tweets, youtube_avg_followers_ct, s=youtube_total_likes*5, color='red', label='You Tube', edgecolors='black', alpha=0.75)\n",
    "SecurityMaster_plot= ax.scatter(SecurityMaster_total_tweets, SecurityMaster_avg_followers_ct, s=SecurityMaster_total_likes*5, color='blueviolet', label='Security Master, Antivirus VPN', edgecolors='black', alpha=0.75)\n",
    "ClashRoyale_plot= ax.scatter(ClashRoyale_total_tweets, ClashRoyale_avg_followers_ct, s=ClashRoyale_total_likes*5, color='darkolivegreen', label='Clash Royale', edgecolors='black', alpha=0.75)\n",
    "whatsapp_plot= ax.scatter(whatsapp_total_tweets, whatsapp_avg_followers_ct, s=whatsapp_total_likes*5, color='tan', label='Whats App', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# Apple Apps Store - 6 apps\n",
    "templerun_plot= ax.scatter(templerun_total_tweets, templerun_avg_followers_ct, s=templerun_total_likes*5, color='lawngreen', label='Temple Run', edgecolors='black', alpha=0.75)\n",
    "pandora_plot= ax.scatter(pandora_total_tweets, pandora_avg_followers_ct, s=pandora_total_likes*5, color='coral', label='Pandora', edgecolors='black', alpha=0.75)\n",
    "pinterest_plot= ax.scatter(pinterest_total_tweets, pinterest_avg_followers_ct, s=pinterest_total_likes*5, color='firebrick', label='Pinterest', edgecolors='black', alpha=0.75)\n",
    "bible_plot= ax.scatter(bible_total_tweets, bible_avg_followers_ct, s=bible_total_likes*5, color='tomato', label='Bible', edgecolors='black', alpha=0.75)\n",
    "spotify_plot= ax.scatter(spotify_total_tweets, spotify_avg_followers_ct, s=spotify_total_likes*5, color='orangered', label='Spotify', edgecolors='black', alpha=0.75)\n",
    "angrybirds_plot= ax.scatter(angrybirds_total_tweets, angrybirds_avg_followers_ct, s=angrybirds_total_likes*5, color='forestgreen', label='Angry Birds', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# title and labels\n",
    "plt.title(\"Tweets vs Average Followers (Mar 27 - Apr 3, 2019) \\n\")\n",
    "plt.xlabel(\"Total Tweets \\n Note: Circle sizes correlate with Total Likes\" )\n",
    "plt.ylabel(\"Average Number of Followers per Twitter User \\n\")\n",
    "\n",
    "# set and format the legend\n",
    "lgnd = plt.legend(title='Legend', loc=\"best\")\n",
    "    \n",
    "\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "lgnd.legendHandles[3]._sizes = [30]\n",
    "lgnd.legendHandles[4]._sizes = [30]\n",
    "lgnd.legendHandles[5]._sizes = [30]\n",
    "lgnd.legendHandles[6]._sizes = [30]\n",
    "lgnd.legendHandles[7]._sizes = [30]\n",
    "lgnd.legendHandles[8]._sizes = [30]\n",
    "lgnd.legendHandles[9]._sizes = [30]\n",
    "lgnd.legendHandles[10]._sizes = [30]\n",
    "lgnd.legendHandles[11]._sizes = [30]\n",
    "lgnd.legendHandles[12]._sizes = [30]\n",
    "lgnd.legendHandles[13]._sizes = [30]\n",
    "lgnd.legendHandles[14]._sizes = [30]\n",
    "lgnd.legendHandles[15]._sizes = [30]\n",
    "\n",
    "\n",
    "#grid lines and show\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#plt.savefig(\"./TWEETS_vs__AVG_followers_Scatter.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Cell: Tried to automate plot, but was unable to beause for the size (s), JG wanted to scale the\n",
    "# the size by multiplying by a unique scale depending on the number of likes to emphasize data points\n",
    "# Conclusion: was to stick with brute force method\n",
    "\n",
    "SubwaySurfers_total_tweets, \n",
    "x = [facebook_total_tweets, instagram_total_tweets, coc_total_tweets,\n",
    "     candycrushsaga_total_tweets, CleanMaster_total_tweets,\n",
    "     youtube_total_tweets, SecurityMaster_total_tweets,\n",
    "     ClashRoyale_total_tweets, whatsapp_total_tweets, templerun_total_tweets,\n",
    "     pandora_total_tweets, pinterest_total_tweets, bible_total_tweets, spotify_total_tweets,\n",
    "     angrybirds_total_tweets]\n",
    "SubwaySurfers_avg_followers_ct, \n",
    "y = [facebook_avg_followers_ct, instagram_avg_followers_ct, coc_avg_followers_ct,\n",
    "     candycrushsaga_avg_followers_ct, CleanMaster_avg_followers_ct,\n",
    "     youtube_avg_followers_ct, SecurityMaster_avg_followers_ct,\n",
    "     ClashRoyale_avg_followers_ct, whatsapp_avg_followers_ct, templerun_avg_followers_ct,\n",
    "     pandora_avg_followers_ct, pinterest_avg_followers_ct, bible_avg_followers_ct, spotify_avg_followers_ct,\n",
    "     angrybirds_avg_followers_ct]\n",
    "\n",
    "\"\"\"\n",
    "# Below this method doesn't work. Will go with brute force method.\n",
    "s = [(facebook_total_likes*15), (instagram_total_likes*15), (coc_total_likes*10), (candycrushsaga_total_likes*5),\n",
    "    (CleanMaster_total_likes*5), (SubwaySurfers_total_likes*5), (youtube_total_likes*5), (SecurityMaster_total_likes*5)\n",
    "    (ClashRoyale_total_likes*5), (whatsapp_total_likes*5), (templerun_total_likes*5), (pandora_total_likes*5),\n",
    "    (pinterest_total_likes*5), (bible_total_likes*5), (spotify_total_likes*5), (angrybirds_total_likes*5)]\n",
    "\"\"\"\n",
    "s = [facebook_total_likes, instagram_total_likes, coc_total_likes, candycrushsaga_total_likes,\n",
    "    CleanMaster_total_likes, SubwaySurfers_total_likes, youtube_total_likes, SecurityMaster_total_likes,\n",
    "    ClashRoyale_total_likes, whatsapp_total_likes, templerun_total_likes, pandora_total_likes,\n",
    "    pinterest_total_likes, bible_total_likes, spotify_total_likes, angrybirds_total_likes]\n",
    "\n",
    "colors = np.random.rand(16)\n",
    "\n",
    "\n",
    "\n",
    "label = []\n",
    "edgecolors = []\n",
    "alpha = []\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,11))\n",
    "ax.scatter(x, y, s)\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "\"\"\"# Apps both on Google Play Store and Apple - 4 apps\n",
    "facebook_plot = ax.scatter(, , , color='sandybrown', label='Facebook', edgecolors='black', alpha=0.75)\n",
    "instagram_plot= ax.scatter(, , , color='saddlebrown', label='Instagram', edgecolors='black', alpha=0.5)\n",
    "coc_plot= ax.scatter(,, , color='springgreen', label='Clash Of Clans', edgecolors='black', alpha=0.75)\n",
    "candycrushsaga_plot= ax.scatter(,, , color='limegreen', label='Candy Crush Saga', edgecolors='black')#, alpha=0.75)\n",
    "\n",
    "# Google Play Store - 6 apps:\n",
    "CleanMaster_plot= ax.scatter(,, , color='m', label='Clean Master Space Cleaner', edgecolors='black', alpha=0.75)\n",
    "SubwaySurfers_plot= ax.scatter(,, , color='lime', label='Subway Surfers', edgecolors='black', alpha=0.75)\n",
    "youtube_plot= ax.scatter(,, , color='red', label='You Tube', edgecolors='black', alpha=0.75)\n",
    "SecurityMaster_plot= ax.scatter(,, , color='blueviolet', label='Security Master, Antivirus VPN', edgecolors='black', alpha=0.75)\n",
    "ClashRoyale_plot= ax.scatter(,, , color='darkolivegreen', label='Clash Royale', edgecolors='black', alpha=0.75)\n",
    "whatsapp_plot= ax.scatter(,, , color='tan', label='Whats App', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# Apple Apps Store - 6 apps\n",
    "templerun_plot= ax.scatter(, , , color='lawngreen', label='Temple Run', edgecolors='black', alpha=0.75)\n",
    "pandora_plot= ax.scatter(, ,, color='coral', label='Pandora', edgecolors='black', alpha=0.75)\n",
    "pinterest_plot= ax.scatter(, ,, color='firebrick', label='Pinterest', edgecolors='black', alpha=0.75)\n",
    "bible_plot= ax.scatter(, , color='tomato', label='Bible', edgecolors='black', alpha=0.75)\n",
    "spotify_plot= ax.scatter(, , color='orangered', label='Spotify', edgecolors='black', alpha=0.75)\n",
    "angrybirds_plot= ax.scatter(,,, color='forestgreen', label='Angry Birds', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# title and labels\n",
    "plt.title(\"Tweets vs Average Followers (Mar 27 - Apr 3, 2019) \\n\")\n",
    "plt.xlabel(\"Total Tweets \\n Note: Circle sizes correlate with Total Likes\" )\n",
    "plt.ylabel(\"Average Number of Followers per Twitter User \\n\")\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot 2 - Tweets vs ReTweets vs Likes\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,11))\n",
    "\n",
    "\n",
    "# Apps both on Google Play Store and Apple - 4 apps\n",
    "facebook_plot = ax.scatter(facebook_total_tweets, facebook_avg_retweets, s=facebook_total_likes*5, color='sandybrown', label='Facebook', edgecolors='black', alpha=0.75)\n",
    "instagram_plot= ax.scatter(instagram_total_tweets, instagram_avg_retweets, s=instagram_total_likes*5, color='saddlebrown', label='Instagram', edgecolors='black', alpha=0.75)\n",
    "coc_plot= ax.scatter(coc_total_tweets, coc_avg_retweets, s=coc_total_likes*5, color='springgreen', label='Clash Of Clans', edgecolors='black', alpha=0.75)\n",
    "candycrushsaga_plot= ax.scatter(candycrushsaga_total_tweets, candycrushsaga_avg_retweets, s=candycrushsaga_total_likes*5, color='limegreen', label='Candy Crush Saga', edgecolors='black')#, alpha=0.75)\n",
    "\n",
    "# Google Play Store - 6 apps:\n",
    "CleanMaster_plot= ax.scatter(CleanMaster_total_tweets, CleanMaster_avg_retweets, s=CleanMaster_total_likes*5, color='m', label='Clean Master Space Cleaner', edgecolors='black', alpha=0.75)\n",
    "SubwaySurfers_plot= ax.scatter(SubwaySurfers_total_tweets, SubwaySurfers_avg_retweets, s=SubwaySurfers_total_likes*5, color='lime', label='Subway Surfers', edgecolors='black', alpha=0.75)\n",
    "youtube_plot= ax.scatter(youtube_total_tweets, youtube_avg_retweets, s=youtube_total_likes*5, color='red', label='You Tube', edgecolors='black', alpha=0.75)\n",
    "SecurityMaster_plot= ax.scatter(SecurityMaster_total_tweets, SecurityMaster_avg_retweets, s=SecurityMaster_total_likes*5, color='blueviolet', label='Security Master, Antivirus VPN', edgecolors='black', alpha=0.75)\n",
    "ClashRoyale_plot= ax.scatter(ClashRoyale_total_tweets, ClashRoyale_avg_retweets, s=ClashRoyale_total_likes*5, color='darkolivegreen', label='Clash Royale', edgecolors='black', alpha=0.75)\n",
    "whatsapp_plot= ax.scatter(whatsapp_total_tweets, whatsapp_avg_retweets, s=whatsapp_total_likes*5, color='tan', label='Whats App', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# Apple Apps Store - 6 apps\n",
    "templerun_plot= ax.scatter(templerun_total_tweets, templerun_avg_retweets, s=templerun_total_likes*5, color='lawngreen', label='Temple Run', edgecolors='black', alpha=0.75)\n",
    "pandora_plot= ax.scatter(pandora_total_tweets, pandora_avg_retweets, s=pandora_total_likes*5, color='coral', label='Pandora', edgecolors='black', alpha=0.75)\n",
    "pinterest_plot= ax.scatter(pinterest_total_tweets, pinterest_avg_retweets, s=pinterest_total_likes*5, color='firebrick', label='Pinterest', edgecolors='black', alpha=0.75)\n",
    "bible_plot= ax.scatter(bible_total_tweets, bible_avg_retweets, s=bible_total_likes*5, color='tomato', label='Bible', edgecolors='black', alpha=0.75)\n",
    "spotify_plot= ax.scatter(spotify_total_tweets, spotify_avg_retweets, s=spotify_total_likes*5, color='orangered', label='Spotify', edgecolors='black', alpha=0.75)\n",
    "angrybirds_plot= ax.scatter(angrybirds_total_tweets, angrybirds_avg_retweets, s=angrybirds_total_likes*5, color='forestgreen', label='Angry Birds', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# title and labels\n",
    "plt.title(\"Tweets vs ReTweets (Mar 27 - Apr 3, 2019) \\n\")\n",
    "plt.xlabel(\"Total Tweets \\n Note: Circle sizes correlate with Total Likes \\n\" )\n",
    "plt.ylabel(\"Average Number of ReTweets per Twitter User \\n\")\n",
    "\n",
    "# set and format the legend\n",
    "lgnd = plt.legend(title='Legend', loc=\"best\")\n",
    "\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "lgnd.legendHandles[3]._sizes = [30]\n",
    "lgnd.legendHandles[4]._sizes = [30]\n",
    "lgnd.legendHandles[5]._sizes = [30]\n",
    "lgnd.legendHandles[6]._sizes = [30]\n",
    "lgnd.legendHandles[7]._sizes = [30]\n",
    "lgnd.legendHandles[8]._sizes = [30]\n",
    "lgnd.legendHandles[9]._sizes = [30]\n",
    "lgnd.legendHandles[10]._sizes = [30]\n",
    "lgnd.legendHandles[11]._sizes = [30]\n",
    "lgnd.legendHandles[12]._sizes = [30]\n",
    "lgnd.legendHandles[13]._sizes = [30]\n",
    "lgnd.legendHandles[14]._sizes = [30]\n",
    "lgnd.legendHandles[15]._sizes = [30]\n",
    "\n",
    "\n",
    "#grid lines and show\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#plt.savefig('./TWEETS_VS_RETWEETS_vs_LIKES_Scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Scatter Plot 3 - Will not use this plot\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "\n",
    "# Apps both on Google Play Store and Apple - 4 apps\n",
    "facebook_plot = ax.scatter(facebook_avg_retweets, facebook_total_tweets, s=facebook_total_likes*5, color='blue', label='Facebook', edgecolors='red', alpha=0.75)\n",
    "instagram_plot= ax.scatter(instagram_avg_retweets, instagram_total_tweets, s=instagram_total_likes*5, color='fuchsia', label='Instagram', edgecolors='red', alpha=0.75)\n",
    "coc_plot= ax.scatter(coc_avg_retweets, coc_total_tweets, s=coc_total_likes*5, color='springgreen', label='Clash Of Clans', edgecolors='red', alpha=0.75)\n",
    "candycrushsaga_plot= ax.scatter(candycrushsaga_avg_retweets, candycrushsaga_total_tweets, s=candycrushsaga_total_likes*5, color='black', label='Candy Crush Saga', edgecolors='red')#, alpha=0.75)\n",
    "\n",
    "# Google Play Store - 6 apps:\n",
    "CleanMaster_plot= ax.scatter(CleanMaster_avg_retweets, CleanMaster_total_tweets, s=CleanMaster_total_likes*5, color='olive', label='Clean Master Space Cleaner', edgecolors='lime', alpha=0.75)\n",
    "SubwaySurfers_plot= ax.scatter(SubwaySurfers_avg_retweets, SubwaySurfers_total_tweets, s=SubwaySurfers_total_likes*5, color='plum', label='Subway Surfers', edgecolors='lime', alpha=0.75)\n",
    "youtube_plot= ax.scatter(youtube_avg_retweets, youtube_total_tweets, s=youtube_total_likes*5, color='grey', label='You Tube', edgecolors='lime', alpha=0.75)\n",
    "SecurityMaster_plot= ax.scatter(SecurityMaster_avg_retweets, SecurityMaster_total_tweets, s=SecurityMaster_total_likes*5, color='coral', label='Security Master, Antivirus VPN', edgecolors='lime', alpha=0.75)\n",
    "ClashRoyale_plot= ax.scatter(ClashRoyale_avg_retweets, ClashRoyale_total_tweets, s=ClashRoyale_total_likes*5, color='orange', label='Clash Royale', edgecolors='lime', alpha=0.75)\n",
    "whatsapp_plot= ax.scatter(whatsapp_avg_retweets, whatsapp_total_tweets, s=whatsapp_total_likes*5, color='green', label='Whats App', edgecolors='lime', alpha=0.75)\n",
    "\n",
    "# Apple Apps Store - 6 apps\n",
    "templerun_plot= ax.scatter(templerun_avg_retweets, templerun_total_tweets, s=templerun_total_likes*5, color='lawngreen', label='Temple Run', edgecolors='black', alpha=0.75)\n",
    "pandora_plot= ax.scatter(pandora_avg_retweets, pandora_total_tweets, s=pandora_total_likes*5, color='cornflowerblue', label='Pandora', edgecolors='black', alpha=0.75)\n",
    "pinterest_plot= ax.scatter(pinterest_avg_retweets, pinterest_total_tweets, s=pinterest_total_likes*5, color='firebrick', label='Pinterest', edgecolors='black', alpha=0.75)\n",
    "bible_plot= ax.scatter(bible_avg_retweets, bible_total_tweets, s=bible_total_likes*5, color='brown', label='Bible', edgecolors='black', alpha=0.75)\n",
    "spotify_plot= ax.scatter(spotify_avg_retweets, spotify_total_tweets, s=spotify_total_likes*5, color='darkgreen', label='Spotify', edgecolors='black', alpha=0.75)\n",
    "angrybirds_plot= ax.scatter(angrybirds_avg_retweets, angrybirds_total_tweets, s=angrybirds_total_likes*5, color='salmon', label='Angry Birds', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# title and labels\n",
    "plt.title(\"Tweets vs ReTweets (Mar 27 - Apr 3, 2019) \\n\")\n",
    "plt.xlabel(\"Total Tweets \\n Note: Circle sizes correlate with Total Likes \\n\" )\n",
    "plt.ylabel(\"Average Number of ReTweets per Twitter User \\n\")\n",
    "\n",
    "# set and format the legend\n",
    "lgnd = plt.legend(title='Legend', loc=\"best\")\n",
    "\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "lgnd.legendHandles[3]._sizes = [30]\n",
    "lgnd.legendHandles[4]._sizes = [30]\n",
    "lgnd.legendHandles[5]._sizes = [30]\n",
    "lgnd.legendHandles[6]._sizes = [30]\n",
    "lgnd.legendHandles[7]._sizes = [30]\n",
    "lgnd.legendHandles[8]._sizes = [30]\n",
    "lgnd.legendHandles[9]._sizes = [30]\n",
    "lgnd.legendHandles[10]._sizes = [30]\n",
    "lgnd.legendHandles[11]._sizes = [30]\n",
    "lgnd.legendHandles[12]._sizes = [30]\n",
    "lgnd.legendHandles[13]._sizes = [30]\n",
    "lgnd.legendHandles[14]._sizes = [30]\n",
    "lgnd.legendHandles[15]._sizes = [30]\n",
    "\n",
    "\n",
    "#grid lines and show\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#plt.savefig('./tweets_vs__avgfollowers_Scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hardcoding numbers from analysis done in Apple and Google Play Store Final Code Notebooks\n",
    "# Avergage Apple, Google Ratings\n",
    "facebook_avg_rating = (3.5 + 4.1)/2\n",
    "instagram_avg_rating = (4.5 + 4.5)/2\n",
    "coc_avg_rating = (4.5 + 4.6)/2\n",
    "candycrushsaga_avg_rating = (4.5 + 4.4)/2\n",
    "\n",
    "# Avergage Apple, Google Reviews\n",
    "facebook_reviews = (2974676 + 78158306)/2\n",
    "instagram_reviews = (2161558 + 66577446)/2\n",
    "coc_reviews = (2130805 + 44893888)/2\n",
    "candycrushsaga_reviews = (961794 + 22430188)/2\n",
    "\n",
    "# Apple App Ratings\n",
    "templerun_rating = 4.5\n",
    "pandora_rating = 4.5\n",
    "pinterest_rating = 4.5\n",
    "bible_rating = 4.5\n",
    "spotify_rating = 4.5\n",
    "angrybirds_rating = 4.5\n",
    "\n",
    "# Apple App Reviews\n",
    "templerun_reviews = 1724546\n",
    "pandora_reviews = 1126879\n",
    "pinterest_reviews = 1061624\n",
    "bible_reviews = 985920\n",
    "spotify_reviews = 878563\n",
    "angrybirds_reviews = 824451\n",
    "\n",
    "\n",
    "# Google App Ratings\n",
    "whatsapp_rating = 4.4\n",
    "clean_master_rating = 4.7\n",
    "subway_surfers_rating = 4.5\n",
    "you_tube_rating = 4.3\n",
    "security_master_rating = 4.7\n",
    "clash_royale_rating = 4.6\n",
    "\n",
    "# Google App Reviews\n",
    "whatsapp_reviews = 69119316\n",
    "clean_master_reviews = 42916526\n",
    "subway_surfers_reviews = 27725352\n",
    "you_tube_reviews = 25655305\n",
    "security_master_reviews = 24900999\n",
    "clash_royale_reviews = 23136735\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot 5 - Tweets vs Ratings vs Likes - USE THIS ONE\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,11))\n",
    "\n",
    "\n",
    "# Apps both on Google Play Store and Apple - 4 apps\n",
    "facebook_plot = ax.scatter(facebook_total_tweets, facebook_avg_rating, s=facebook_total_likes*5, color='sandybrown', label='Facebook', edgecolors='black', alpha=0.75)\n",
    "instagram_plot= ax.scatter(instagram_total_tweets, instagram_avg_rating, s=instagram_total_likes*5, color='saddlebrown', label='Instagram', edgecolors='black', alpha=0.75)\n",
    "coc_plot= ax.scatter(coc_total_tweets, coc_avg_rating, s=coc_total_likes*5, color='springgreen', label='Clash Of Clans', edgecolors='black', alpha=0.75)\n",
    "candycrushsaga_plot= ax.scatter(candycrushsaga_total_tweets, candycrushsaga_avg_rating, s=candycrushsaga_total_likes*5, color='limegreen', label='Candy Crush Saga', edgecolors='black')#, alpha=0.75)\n",
    "\n",
    "# Google Play Store - 6 apps:\n",
    "CleanMaster_plot= ax.scatter(CleanMaster_total_tweets, clean_master_rating, s=CleanMaster_total_likes*5, color='m', label='Clean Master Space Cleaner', edgecolors='black', alpha=0.75)\n",
    "SubwaySurfers_plot= ax.scatter(SubwaySurfers_total_tweets, subway_surfers_rating, s=SubwaySurfers_total_likes*5, color='lime', label='Subway Surfers', edgecolors='black', alpha=0.75)\n",
    "youtube_plot= ax.scatter(youtube_total_tweets, you_tube_rating, s=youtube_total_likes*5, color='red', label='You Tube', edgecolors='black', alpha=0.75)\n",
    "SecurityMaster_plot= ax.scatter(SecurityMaster_total_tweets, security_master_rating, s=SecurityMaster_total_likes*5, color='blueviolet', label='Security Master, Antivirus VPN', edgecolors='black', alpha=0.75)\n",
    "ClashRoyale_plot= ax.scatter(ClashRoyale_total_tweets, clash_royale_rating, s=ClashRoyale_total_likes*5, color='darkolivegreen', label='Clash Royale', edgecolors='black', alpha=0.75)\n",
    "whatsapp_plot= ax.scatter(whatsapp_total_tweets, whatsapp_rating, s=whatsapp_total_likes*5, color='tan', label='Whats App', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# Apple Apps Store - 6 apps\n",
    "templerun_plot= ax.scatter(templerun_total_tweets,templerun_rating, s=templerun_total_likes*5, color='lawngreen', label='Temple Run', edgecolors='black', alpha=0.75)\n",
    "pandora_plot= ax.scatter(pandora_total_tweets, pandora_rating, s=pandora_total_likes*5, color='coral', label='Pandora', edgecolors='black', alpha=0.75)\n",
    "pinterest_plot= ax.scatter(pinterest_total_tweets, pinterest_rating, s=pinterest_total_likes*5, color='firebrick', label='Pinterest', edgecolors='black', alpha=0.75)\n",
    "bible_plot= ax.scatter(bible_total_tweets, bible_rating, s=bible_total_likes*5, color='tomato', label='Bible', edgecolors='black', alpha=0.75)\n",
    "spotify_plot= ax.scatter(spotify_total_tweets, spotify_rating, s=spotify_total_likes*5, color='orangered', label='Spotify', edgecolors='black', alpha=0.75)\n",
    "angrybirds_plot= ax.scatter(angrybirds_total_tweets, angrybirds_rating, s=angrybirds_total_likes*5, color='forestgreen', label='Angry Birds', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# title and labels\n",
    "plt.title(\"Tweets vs Ratings (Mar 27 - Apr 3, 2019) \\n\")\n",
    "plt.xlabel(\"Total Tweets \\n Note: Circle sizes correlate with Total Likes \\n\" )\n",
    "plt.ylabel(\"App Store User Ratings (Out of 5) \\n\")\n",
    "\n",
    "# set and format the legend\n",
    "lgnd = plt.legend(title='Legend', loc=\"best\")\n",
    "\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "lgnd.legendHandles[3]._sizes = [30]\n",
    "lgnd.legendHandles[4]._sizes = [30]\n",
    "lgnd.legendHandles[5]._sizes = [30]\n",
    "lgnd.legendHandles[6]._sizes = [30]\n",
    "lgnd.legendHandles[7]._sizes = [30]\n",
    "lgnd.legendHandles[8]._sizes = [30]\n",
    "lgnd.legendHandles[9]._sizes = [30]\n",
    "lgnd.legendHandles[10]._sizes = [30]\n",
    "lgnd.legendHandles[11]._sizes = [30]\n",
    "lgnd.legendHandles[12]._sizes = [30]\n",
    "lgnd.legendHandles[13]._sizes = [30]\n",
    "lgnd.legendHandles[14]._sizes = [30]\n",
    "lgnd.legendHandles[15]._sizes = [30]\n",
    "\n",
    "\n",
    "#grid lines and show\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#plt.savefig('./TWEETS_VS_RATINGSVS LIKES_Scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot 5 - Tweets vs Reviews vs Ratings (size) - DO NOT USE\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,11))\n",
    "\n",
    "\n",
    "\n",
    "# Apps both on Google Play Store and Apple - 4 apps\n",
    "facebook_plot = ax.scatter(facebook_total_tweets, facebook_reviews, s=facebook_avg_rating*105, color='sandybrown', label='Facebook', edgecolors='black', alpha=0.75)\n",
    "instagram_plot= ax.scatter(instagram_total_tweets, instagram_reviews, s=instagram_avg_rating*105, color='saddlebrown', label='Instagram', edgecolors='black', alpha=0.75)\n",
    "coc_plot= ax.scatter(coc_total_tweets, coc_reviews, s=coc_avg_rating*105, color='springgreen', label='Clash Of Clans', edgecolors='black', alpha=0.75)\n",
    "candycrushsaga_plot= ax.scatter(candycrushsaga_total_tweets, candycrushsaga_reviews, s=candycrushsaga_avg_rating*105, color='limegreen', label='Candy Crush Saga', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# Google Play Store - 6 apps:\n",
    "CleanMaster_plot= ax.scatter(CleanMaster_total_tweets, clean_master_reviews, s=clean_master_rating*105, color='m', label='Clean Master Space Cleaner', edgecolors='black', alpha=0.75)\n",
    "SubwaySurfers_plot= ax.scatter(SubwaySurfers_total_tweets, subway_surfers_reviews, s=subway_surfers_rating*105, color='lime', label='Subway Surfers', edgecolors='black', alpha=0.75)\n",
    "youtube_plot= ax.scatter(youtube_total_tweets, you_tube_reviews, s=you_tube_rating*105, color='red', label='You Tube', edgecolors='black', alpha=0.75)\n",
    "SecurityMaster_plot= ax.scatter(SecurityMaster_total_tweets, security_master_reviews, s=security_master_rating*105, color='blueviolet', label='Security Master, Antivirus VPN', edgecolors='black', alpha=0.75)\n",
    "ClashRoyale_plot= ax.scatter(ClashRoyale_total_tweets, clash_royale_reviews, s=clash_royale_rating*105, color='darkolivegreen', label='Clash Royale', edgecolors='black', alpha=0.75)\n",
    "whatsapp_plot= ax.scatter(whatsapp_total_tweets, whatsapp_reviews, s=whatsapp_rating*105, color='tan', label='Whats App', edgecolors='lime', alpha=0.75)\n",
    "\n",
    "# Apple Apps Store - 6 apps\n",
    "templerun_plot= ax.scatter(templerun_total_tweets,templerun_reviews, s=templerun_rating*105, color='lawngreen', label='Temple Run', edgecolors='black', alpha=0.75)\n",
    "pandora_plot= ax.scatter(pandora_total_tweets, pandora_reviews, s=pandora_rating*105, color='coral', label='Pandora', edgecolors='black', alpha=0.75)\n",
    "pinterest_plot= ax.scatter(pinterest_total_tweets, pinterest_reviews, s=pinterest_rating*105, color='firebrick', label='Pinterest', edgecolors='black', alpha=0.75)\n",
    "bible_plot= ax.scatter(bible_total_tweets, bible_reviews, s=bible_rating*105, color='tomato', label='Bible', edgecolors='black', alpha=0.75)\n",
    "spotify_plot= ax.scatter(spotify_total_tweets, spotify_reviews, s=spotify_rating*105, color='orangered', label='Spotify', edgecolors='black', alpha=0.75)\n",
    "angrybirds_plot= ax.scatter(angrybirds_total_tweets, angrybirds_reviews, s=angrybirds_rating*105, color='forestgreen', label='Angry Birds', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# title and labels\n",
    "plt.title(\"Tweets vs Reviews (Mar 27 - Apr 3, 2019) \\n\")\n",
    "plt.xlabel(\"Total Tweets \\n Note: Circle sizes correlate with App Ratings \\n\" )\n",
    "plt.ylabel(\"App Store Reviews in Millions \\n\")\n",
    "\n",
    "# set and format the legend\n",
    "lgnd = plt.legend(title='Legend', loc=\"best\")\n",
    "\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "lgnd.legendHandles[3]._sizes = [30]\n",
    "lgnd.legendHandles[4]._sizes = [30]\n",
    "lgnd.legendHandles[5]._sizes = [30]\n",
    "lgnd.legendHandles[6]._sizes = [30]\n",
    "lgnd.legendHandles[7]._sizes = [30]\n",
    "lgnd.legendHandles[8]._sizes = [30]\n",
    "lgnd.legendHandles[9]._sizes = [30]\n",
    "lgnd.legendHandles[10]._sizes = [30]\n",
    "lgnd.legendHandles[11]._sizes = [30]\n",
    "lgnd.legendHandles[12]._sizes = [30]\n",
    "lgnd.legendHandles[13]._sizes = [30]\n",
    "lgnd.legendHandles[14]._sizes = [30]\n",
    "lgnd.legendHandles[15]._sizes = [30]\n",
    "\n",
    "\n",
    "#grid lines and show\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#plt.savefig('./tweets_vs__avgfollowers_Scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot 6 - Tweets vs Reviews vs Likes (size) -USE THIS ONE\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11,11))\n",
    "\n",
    "\n",
    "\n",
    "# Apps both on Google Play Store and Apple - 4 apps\n",
    "facebook_plot = ax.scatter(facebook_total_tweets, facebook_reviews, s=facebook_total_likes*5, color='sandybrown', label='Facebook', edgecolors='black', alpha=0.75)\n",
    "instagram_plot= ax.scatter(instagram_total_tweets, instagram_reviews, s=instagram_total_likes*5, color='saddlebrown', label='Instagram', edgecolors='black', alpha=0.75)\n",
    "coc_plot= ax.scatter(coc_total_tweets, coc_reviews, s=coc_total_likes*5, color='springgreen', label='Clash Of Clans', edgecolors='black', alpha=0.75)\n",
    "candycrushsaga_plot= ax.scatter(candycrushsaga_total_tweets, candycrushsaga_reviews, s=candycrushsaga_total_likes*5, color='limegreen', label='Candy Crush Saga', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# Google Play Store - 6 apps:\n",
    "CleanMaster_plot= ax.scatter(CleanMaster_total_tweets, clean_master_reviews, s=CleanMaster_total_likes*5, color='m', label='Clean Master Space Cleaner', edgecolors='black', alpha=0.75)\n",
    "SubwaySurfers_plot= ax.scatter(SubwaySurfers_total_tweets, subway_surfers_reviews, s=SubwaySurfers_total_likes*5, color='lime', label='Subway Surfers', edgecolors='black', alpha=0.75)\n",
    "youtube_plot= ax.scatter(youtube_total_tweets, you_tube_reviews, s=youtube_total_likes*5, color='red', label='You Tube', edgecolors='black', alpha=0.75)\n",
    "SecurityMaster_plot= ax.scatter(SecurityMaster_total_tweets, security_master_reviews, s=SecurityMaster_total_likes*5, color='blueviolet', label='Security Master, Antivirus VPN', edgecolors='black', alpha=0.75)\n",
    "ClashRoyale_plot= ax.scatter(ClashRoyale_total_tweets, clash_royale_reviews, s=ClashRoyale_total_likes*5, color='darkolivegreen', label='Clash Royale', edgecolors='black', alpha=0.75)\n",
    "whatsapp_plot= ax.scatter(whatsapp_total_tweets, whatsapp_reviews, s=whatsapp_total_likes*5, color='tan', label='Whats App', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# Apple Apps Store - 6 apps\n",
    "templerun_plot= ax.scatter(templerun_total_tweets, templerun_reviews, s=templerun_total_likes*5, color='lawngreen', label='Temple Run', edgecolors='black', alpha=0.75)\n",
    "pandora_plot= ax.scatter(pandora_total_tweets, pandora_reviews, s=pandora_total_likes*5, color='coral', label='Pandora', edgecolors='black', alpha=0.75)\n",
    "pinterest_plot= ax.scatter(pinterest_total_tweets, pinterest_reviews, s=pinterest_total_likes*5, color='firebrick', label='Pinterest', edgecolors='black', alpha=0.75)\n",
    "bible_plot= ax.scatter(bible_total_tweets, bible_reviews, s=bible_total_likes*5, color='tomato', label='Bible', edgecolors='black', alpha=0.75)\n",
    "spotify_plot= ax.scatter(spotify_total_tweets, spotify_reviews, s=spotify_total_likes*5, color='orangered', label='Spotify', edgecolors='black', alpha=0.75)\n",
    "angrybirds_plot= ax.scatter(angrybirds_total_tweets, angrybirds_reviews, s=angrybirds_total_likes*5, color='forestgreen', label='Angry Birds', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# title and labels\n",
    "plt.title(\"Tweets vs Reviews (Mar 27 - Apr 3, 2019) \\n\")\n",
    "plt.xlabel(\"Total Tweets \\n Note: Circle sizes correlate with Likes \\n\" )\n",
    "plt.ylabel(\"App Store Reviews in Millions \\n\")\n",
    "\n",
    "# set and format the legend\n",
    "lgnd = plt.legend(title='Legend', loc=\"best\")\n",
    "\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "lgnd.legendHandles[3]._sizes = [30]\n",
    "lgnd.legendHandles[4]._sizes = [30]\n",
    "lgnd.legendHandles[5]._sizes = [30]\n",
    "lgnd.legendHandles[6]._sizes = [30]\n",
    "lgnd.legendHandles[7]._sizes = [30]\n",
    "lgnd.legendHandles[8]._sizes = [30]\n",
    "lgnd.legendHandles[9]._sizes = [30]\n",
    "lgnd.legendHandles[10]._sizes = [30]\n",
    "lgnd.legendHandles[11]._sizes = [30]\n",
    "lgnd.legendHandles[12]._sizes = [30]\n",
    "lgnd.legendHandles[13]._sizes = [30]\n",
    "lgnd.legendHandles[14]._sizes = [30]\n",
    "lgnd.legendHandles[15]._sizes = [30]\n",
    "\n",
    "\n",
    "#grid lines and show\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#plt.savefig('./TWEETS_VS_REVIEWS_VSLIKES_Scatter.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter Plot 5 - Tweets vs Reviews vs Likes (size) - Need to do\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,8))\n",
    "\n",
    "\n",
    "# Apps both on Google Play Store and Apple - 4 apps\n",
    "facebook_plot = ax.scatter(facebook_avg_retweets, facebook_total_tweets, s=facebook_total_likes*5, color='blue', label='Facebook', edgecolors='red', alpha=0.75)\n",
    "instagram_plot= ax.scatter(instagram_avg_retweets, instagram_total_tweets, s=instagram_total_likes*5, color='fuchsia', label='Instagram', edgecolors='red', alpha=0.75)\n",
    "coc_plot= ax.scatter(coc_avg_retweets, coc_total_tweets, s=coc_total_likes*5, color='springgreen', label='Clash Of Clans', edgecolors='red', alpha=0.75)\n",
    "candycrushsaga_plot= ax.scatter(candycrushsaga_avg_retweets, candycrushsaga_total_tweets, s=candycrushsaga_total_likes*5, color='black', label='Candy Crush Saga', edgecolors='red')#, alpha=0.75)\n",
    "\n",
    "# Google Play Store - 6 apps:\n",
    "CleanMaster_plot= ax.scatter(CleanMaster_avg_retweets, CleanMaster_total_tweets, s=CleanMaster_total_likes*5, color='olive', label='Clean Master Space Cleaner', edgecolors='lime', alpha=0.75)\n",
    "SubwaySurfers_plot= ax.scatter(SubwaySurfers_avg_retweets, SubwaySurfers_total_tweets, s=SubwaySurfers_total_likes*5, color='plum', label='Subway Surfers', edgecolors='lime', alpha=0.75)\n",
    "youtube_plot= ax.scatter(youtube_avg_retweets, youtube_total_tweets, s=youtube_total_likes*5, color='grey', label='You Tube', edgecolors='lime', alpha=0.75)\n",
    "SecurityMaster_plot= ax.scatter(SecurityMaster_avg_retweets, SecurityMaster_total_tweets, s=SecurityMaster_total_likes*5, color='coral', label='Security Master, Antivirus VPN', edgecolors='lime', alpha=0.75)\n",
    "ClashRoyale_plot= ax.scatter(ClashRoyale_avg_retweets, ClashRoyale_total_tweets, s=ClashRoyale_total_likes*5, color='orange', label='Clash Royale', edgecolors='lime', alpha=0.75)\n",
    "whatsapp_plot= ax.scatter(whatsapp_avg_retweets, whatsapp_total_tweets, s=whatsapp_total_likes*5, color='green', label='Whats App', edgecolors='lime', alpha=0.75)\n",
    "\n",
    "# Apple Apps Store - 6 apps\n",
    "templerun_plot= ax.scatter(templerun_avg_retweets, templerun_total_tweets, s=templerun_total_likes*5, color='lawngreen', label='Temple Run', edgecolors='black', alpha=0.75)\n",
    "pandora_plot= ax.scatter(pandora_avg_retweets, pandora_total_tweets, s=pandora_total_likes*5, color='cornflowerblue', label='Pandora', edgecolors='black', alpha=0.75)\n",
    "pinterest_plot= ax.scatter(pinterest_avg_retweets, pinterest_total_tweets, s=pinterest_total_likes*5, color='firebrick', label='Pinterest', edgecolors='black', alpha=0.75)\n",
    "bible_plot= ax.scatter(bible_avg_retweets, bible_total_tweets, s=bible_total_likes*5, color='brown', label='Bible', edgecolors='black', alpha=0.75)\n",
    "spotify_plot= ax.scatter(spotify_avg_retweets, spotify_total_tweets, s=spotify_total_likes*5, color='darkgreen', label='Spotify', edgecolors='black', alpha=0.75)\n",
    "angrybirds_plot= ax.scatter(angrybirds_avg_retweets, angrybirds_total_tweets, s=angrybirds_total_likes*5, color='salmon', label='Angry Birds', edgecolors='black', alpha=0.75)\n",
    "\n",
    "# title and labels\n",
    "plt.title(\"Tweets vs ReTweets (Mar 27 - Apr 3, 2019) \\n\")\n",
    "plt.xlabel(\"Avg ReTweets \\n Note: Circle sizes correlate with Total Likes \\n\" )\n",
    "plt.ylabel(\"Total Tweets \\n\")\n",
    "\n",
    "# set and format the legend\n",
    "lgnd = plt.legend(title='Legend', loc=\"best\")\n",
    "\n",
    "lgnd.legendHandles[0]._sizes = [30]\n",
    "lgnd.legendHandles[1]._sizes = [30]\n",
    "lgnd.legendHandles[2]._sizes = [30]\n",
    "lgnd.legendHandles[3]._sizes = [30]\n",
    "lgnd.legendHandles[4]._sizes = [30]\n",
    "lgnd.legendHandles[5]._sizes = [30]\n",
    "lgnd.legendHandles[6]._sizes = [30]\n",
    "lgnd.legendHandles[7]._sizes = [30]\n",
    "lgnd.legendHandles[8]._sizes = [30]\n",
    "lgnd.legendHandles[9]._sizes = [30]\n",
    "lgnd.legendHandles[10]._sizes = [30]\n",
    "lgnd.legendHandles[11]._sizes = [30]\n",
    "lgnd.legendHandles[12]._sizes = [30]\n",
    "lgnd.legendHandles[13]._sizes = [30]\n",
    "lgnd.legendHandles[14]._sizes = [30]\n",
    "lgnd.legendHandles[15]._sizes = [30]\n",
    "\n",
    "\n",
    "#grid lines and show\n",
    "plt.grid()\n",
    "plt.show()\n",
    "#plt.savefig('./tweets_vs__avgfollowers_Scatter.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
